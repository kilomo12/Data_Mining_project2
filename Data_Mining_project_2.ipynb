{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project 2 - Complete Analysis\n",
    "\n",
    "This notebook delivers a complete project workflow for the **CMI Problematic Internet Use** tabular dataset.\n",
    "\n",
    "Covered modules:\n",
    "1. data understanding and preparation\n",
    "2. outlier analysis and treatment\n",
    "3. imbalanced learning strategies\n",
    "4. advanced classification (multiclass target `sii`)\n",
    "5. model explainability and error analysis\n",
    "6. additional advanced tasks: regression and clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Dataset files used:\n",
    "- `cmi_internet.csv`\n",
    "- `data_dictionary.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Resolve file paths (project-relative first)\n",
    "data_path_rel = Path('dm2_25_26_dataset_tabular/DM2_project/cmi_internet.csv')\n",
    "dict_path_rel = Path('dm2_25_26_dataset_tabular/DM2_project/data_dictionary.csv')\n",
    "\n",
    "data_path_fallback = Path('C:/Users/steve/Downloads/Data_Mining_project2/dm2_25_26_dataset_tabular/DM2_project/cmi_internet.csv')\n",
    "dict_path_fallback = Path('C:/Users/steve/Downloads/Data_Mining_project2/dm2_25_26_dataset_tabular/DM2_project/data_dictionary.csv')\n",
    "\n",
    "if data_path_rel.exists():\n",
    "    data_path = data_path_rel\n",
    "elif data_path_fallback.exists():\n",
    "    data_path = data_path_fallback\n",
    "else:\n",
    "    raise FileNotFoundError('Dataset file not found')\n",
    "\n",
    "if dict_path_rel.exists():\n",
    "    dict_path = dict_path_rel\n",
    "elif dict_path_fallback.exists():\n",
    "    dict_path = dict_path_fallback\n",
    "else:\n",
    "    dict_path = None\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df_original = df.copy()\n",
    "\n",
    "print('Data path:', data_path)\n",
    "print('Shape:', df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optional: read data dictionary for feature semantics\n",
    "if dict_path is not None:\n",
    "    data_dictionary = pd.read_csv(dict_path)\n",
    "    print('Data dictionary shape:', data_dictionary.shape)\n",
    "    display(data_dictionary.head(10))\n",
    "else:\n",
    "    print('Data dictionary not found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding and Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Basic structure checks\n",
    "display(df.info())\n",
    "\n",
    "print('Number of duplicated rows:', df.duplicated().sum())\n",
    "print('Number of columns:', df.shape[1])\n",
    "print('Number of records:', df.shape[0])\n",
    "\n",
    "# Identify key columns\n",
    "target_col = 'sii'\n",
    "id_col = 'id' if 'id' in df.columns else None\n",
    "\n",
    "print('Target column:', target_col)\n",
    "print('ID column:', id_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Missing values profile\n",
    "missing_count = df.isna().sum()\n",
    "missing_pct = (missing_count / len(df) * 100).sort_values(ascending=False)\n",
    "\n",
    "print('Columns with missing values:', int((missing_count > 0).sum()))\n",
    "print('Top missing columns:')\n",
    "display(missing_pct.head(20).to_frame('missing_pct'))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Class imbalance profile for the target\n",
    "class_counts = df[target_col].value_counts().sort_index()\n",
    "class_pct = (class_counts / class_counts.sum() * 100).round(2)\n",
    "\n",
    "print('Class counts:')\n",
    "print(class_counts)\n",
    "print()\n",
    "print('Class percentages:')\n",
    "print(class_pct)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.barplot(x=class_counts.index.astype(int), y=class_counts.values, ax=ax[0], palette='viridis')\n",
    "ax[0].set_title('Target Distribution (Counts)')\n",
    "ax[0].set_xlabel('sii class')\n",
    "ax[0].set_ylabel('count')\n",
    "\n",
    "ax[1].pie(class_counts.values, labels=class_counts.index.astype(int), autopct='%1.1f%%', startangle=90)\n",
    "ax[1].set_title('Target Distribution (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Leakage check: PCIAT total score is used to derive severity categories and is strongly tied to sii\n",
    "pciat_cols = [c for c in df.columns if c.startswith('PCIAT-')]\n",
    "print('PCIAT columns found:', len(pciat_cols))\n",
    "\n",
    "if 'PCIAT-PCIAT_Total' in df.columns:\n",
    "    relation = df[['sii', 'PCIAT-PCIAT_Total']].dropna()\n",
    "    print('Rows with non-null PCIAT total:', len(relation))\n",
    "    display(relation.groupby('sii')['PCIAT-PCIAT_Total'].describe()[['count', 'mean', 'min', 'max']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Feature Sets\n",
    "\n",
    "We evaluate two feature spaces:\n",
    "- **full features**: includes `PCIAT-*` variables (high leakage risk)\n",
    "- **no-leak features**: excludes `PCIAT-*` variables (more realistic prediction setting)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build feature matrices\n",
    "full_drop = [target_col] + ([id_col] if id_col else [])\n",
    "X_full = df.drop(columns=full_drop, errors='ignore')\n",
    "\n",
    "no_leak_drop = full_drop + pciat_cols\n",
    "X_no_leak = df.drop(columns=no_leak_drop, errors='ignore')\n",
    "\n",
    "y = df[target_col].astype(int)\n",
    "\n",
    "print('X_full shape:', X_full.shape)\n",
    "print('X_no_leak shape:', X_no_leak.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reusable helpers\n",
    "\n",
    "def make_preprocessor(X):\n",
    "    numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def fit_eval_classifier(model_name, estimator, X_train, y_train, X_test, y_test):\n",
    "    preprocessor = make_preprocessor(X_train)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('model', estimator),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n",
    "        'macro_f1': f1_score(y_test, y_pred, average='macro'),\n",
    "        'weighted_f1': f1_score(y_test, y_pred, average='weighted'),\n",
    "    }\n",
    "\n",
    "    return pipe, y_pred, metrics\n",
    "\n",
    "\n",
    "def crossval_macro_f1(estimator, X, y, folds=3):\n",
    "    preprocessor = make_preprocessor(X)\n",
    "    pipe = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('model', estimator),\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=folds, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scoring = {\n",
    "        'macro_f1': 'f1_macro',\n",
    "        'bal_acc': 'balanced_accuracy',\n",
    "        'acc': 'accuracy',\n",
    "    }\n",
    "\n",
    "    scores = cross_validate(pipe, X, y, cv=cv, scoring=scoring)\n",
    "    return {\n",
    "        'cv_macro_f1_mean': scores['test_macro_f1'].mean(),\n",
    "        'cv_macro_f1_std': scores['test_macro_f1'].std(),\n",
    "        'cv_bal_acc_mean': scores['test_bal_acc'].mean(),\n",
    "        'cv_acc_mean': scores['test_acc'].mean(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split data for both tracks\n",
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(\n",
    "    X_full, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "Xn_train, Xn_test, yn_train, yn_test = train_test_split(\n",
    "    X_no_leak, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print('Full train/test:', Xf_train.shape, Xf_test.shape)\n",
    "print('No-leak train/test:', Xn_train.shape, Xn_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Baseline models\n",
    "base_models = {\n",
    "    'dummy_prior': DummyClassifier(strategy='prior', random_state=RANDOM_STATE),\n",
    "    'logistic_regression': LogisticRegression(max_iter=1200),\n",
    "    'decision_tree': DecisionTreeClassifier(random_state=RANDOM_STATE, min_samples_leaf=10),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "fitted_models = {}\n",
    "predictions = {}\n",
    "\n",
    "# Evaluate on FULL feature space\n",
    "for name, model in base_models.items():\n",
    "    fit_pipe, y_pred, m = fit_eval_classifier(\n",
    "        model_name=f'full::{name}',\n",
    "        estimator=model,\n",
    "        X_train=Xf_train,\n",
    "        y_train=yf_train,\n",
    "        X_test=Xf_test,\n",
    "        y_test=yf_test,\n",
    "    )\n",
    "    rows.append(m)\n",
    "    fitted_models[m['model']] = fit_pipe\n",
    "    predictions[m['model']] = y_pred\n",
    "\n",
    "# Evaluate on NO-LEAK feature space\n",
    "for name, model in base_models.items():\n",
    "    fit_pipe, y_pred, m = fit_eval_classifier(\n",
    "        model_name=f'noleak::{name}',\n",
    "        estimator=model,\n",
    "        X_train=Xn_train,\n",
    "        y_train=yn_train,\n",
    "        X_test=Xn_test,\n",
    "        y_test=yn_test,\n",
    "    )\n",
    "    rows.append(m)\n",
    "    fitted_models[m['model']] = fit_pipe\n",
    "    predictions[m['model']] = y_pred\n",
    "\n",
    "baseline_comparison = pd.DataFrame(rows).sort_values('macro_f1', ascending=False)\n",
    "display(baseline_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cross-validation on the no-leak setting for more robust model selection\n",
    "cv_rows = []\n",
    "\n",
    "for name, model in base_models.items():\n",
    "    cv_stats = crossval_macro_f1(model, X_no_leak, y, folds=3)\n",
    "    cv_rows.append({'model': f'noleak::{name}', **cv_stats})\n",
    "\n",
    "cv_df = pd.DataFrame(cv_rows).sort_values('cv_macro_f1_mean', ascending=False)\n",
    "display(cv_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Outlier Analysis and Treatment\n",
    "\n",
    "Outlier detection is done on numeric training features using `IsolationForest`, then we compare model quality before/after filtering outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Detect outliers on training numeric data (no-leak track)\n",
    "num_cols_noleak = Xn_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "train_num = Xn_train[num_cols_noleak].copy()\n",
    "train_num = train_num.fillna(train_num.median())\n",
    "\n",
    "iso = IsolationForest(contamination=0.03, random_state=RANDOM_STATE)\n",
    "iso_flags = iso.fit_predict(train_num)\n",
    "inlier_mask = (iso_flags == 1)\n",
    "\n",
    "Xn_train_inlier = Xn_train.loc[inlier_mask]\n",
    "yn_train_inlier = yn_train.loc[inlier_mask]\n",
    "\n",
    "print('Original no-leak training size:', len(Xn_train))\n",
    "print('Inlier training size:', len(Xn_train_inlier))\n",
    "print('Removed outliers:', int((~inlier_mask).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compare outlier handling impact with Decision Tree and Random Forest\n",
    "outlier_eval_rows = []\n",
    "\n",
    "for model_name, estimator in {\n",
    "    'decision_tree': DecisionTreeClassifier(random_state=RANDOM_STATE, min_samples_leaf=10),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "}.items():\n",
    "    _, _, m_clean = fit_eval_classifier(\n",
    "        f'noleak_clean::{model_name}', estimator, Xn_train, yn_train, Xn_test, yn_test\n",
    "    )\n",
    "    _, _, m_inlier = fit_eval_classifier(\n",
    "        f'noleak_inlier::{model_name}', estimator, Xn_train_inlier, yn_train_inlier, Xn_test, yn_test\n",
    "    )\n",
    "    outlier_eval_rows.extend([m_clean, m_inlier])\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_eval_rows).sort_values('macro_f1', ascending=False)\n",
    "display(outlier_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Imbalanced Learning Strategies (No-Leak Track)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Algorithm-level balancing with class weights\n",
    "weighted_models = {\n",
    "    'noleak::logreg_weighted': LogisticRegression(max_iter=1200, class_weight='balanced'),\n",
    "    'noleak::dtree_weighted': DecisionTreeClassifier(random_state=RANDOM_STATE, min_samples_leaf=10, class_weight='balanced'),\n",
    "    'noleak::rf_weighted': RandomForestClassifier(\n",
    "        n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1, class_weight='balanced_subsample'\n",
    "    ),\n",
    "}\n",
    "\n",
    "weighted_rows = []\n",
    "weighted_fitted = {}\n",
    "weighted_preds = {}\n",
    "\n",
    "for model_name, estimator in weighted_models.items():\n",
    "    fit_pipe, y_pred, m = fit_eval_classifier(\n",
    "        model_name=model_name,\n",
    "        estimator=estimator,\n",
    "        X_train=Xn_train,\n",
    "        y_train=yn_train,\n",
    "        X_test=Xn_test,\n",
    "        y_test=yn_test,\n",
    "    )\n",
    "    weighted_rows.append(m)\n",
    "    weighted_fitted[model_name] = fit_pipe\n",
    "    weighted_preds[model_name] = y_pred\n",
    "\n",
    "weighted_df = pd.DataFrame(weighted_rows).sort_values('macro_f1', ascending=False)\n",
    "display(weighted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Manual random resampling (train only) so notebook runs without extra libraries\n",
    "\n",
    "def random_oversample(X_in, y_in, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    work = X_in.copy()\n",
    "    work['_target_'] = y_in.values\n",
    "\n",
    "    class_counts = work['_target_'].value_counts()\n",
    "    majority_size = class_counts.max()\n",
    "\n",
    "    parts = []\n",
    "    for cls, count in class_counts.items():\n",
    "        cls_rows = work[work['_target_'] == cls]\n",
    "        if count < majority_size:\n",
    "            extra_idx = rng.choice(cls_rows.index.to_numpy(), size=majority_size - count, replace=True)\n",
    "            cls_rows = pd.concat([cls_rows, cls_rows.loc[extra_idx]], axis=0)\n",
    "        parts.append(cls_rows)\n",
    "\n",
    "    sampled = pd.concat(parts, axis=0).sample(frac=1.0, random_state=random_state)\n",
    "    return sampled.drop(columns=['_target_']), sampled['_target_'].astype(int)\n",
    "\n",
    "\n",
    "def random_undersample(X_in, y_in, random_state=42):\n",
    "    work = X_in.copy()\n",
    "    work['_target_'] = y_in.values\n",
    "\n",
    "    class_counts = work['_target_'].value_counts()\n",
    "    minority_size = class_counts.min()\n",
    "\n",
    "    parts = []\n",
    "    for cls in class_counts.index:\n",
    "        cls_rows = work[work['_target_'] == cls].sample(n=minority_size, replace=False, random_state=random_state)\n",
    "        parts.append(cls_rows)\n",
    "\n",
    "    sampled = pd.concat(parts, axis=0).sample(frac=1.0, random_state=random_state)\n",
    "    return sampled.drop(columns=['_target_']), sampled['_target_'].astype(int)\n",
    "\n",
    "\n",
    "X_over, y_over = random_oversample(Xn_train, yn_train, random_state=RANDOM_STATE)\n",
    "X_under, y_under = random_undersample(Xn_train, yn_train, random_state=RANDOM_STATE)\n",
    "\n",
    "print('Original class distribution:')\n",
    "print(yn_train.value_counts().sort_index())\n",
    "print()\n",
    "print('Oversampled class distribution:')\n",
    "print(y_over.value_counts().sort_index())\n",
    "print()\n",
    "print('Undersampled class distribution:')\n",
    "print(y_under.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate resampling strategies with Random Forest\n",
    "resampling_rows = []\n",
    "\n",
    "rf_est = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "_, y_pred_over, m_over = fit_eval_classifier(\n",
    "    model_name='noleak::rf_oversampled',\n",
    "    estimator=rf_est,\n",
    "    X_train=X_over,\n",
    "    y_train=y_over,\n",
    "    X_test=Xn_test,\n",
    "    y_test=yn_test,\n",
    ")\n",
    "\n",
    "_, y_pred_under, m_under = fit_eval_classifier(\n",
    "    model_name='noleak::rf_undersampled',\n",
    "    estimator=rf_est,\n",
    "    X_train=X_under,\n",
    "    y_train=y_under,\n",
    "    X_test=Xn_test,\n",
    "    y_test=yn_test,\n",
    ")\n",
    "\n",
    "resampling_rows.extend([m_over, m_under])\n",
    "resampling_df = pd.DataFrame(resampling_rows).sort_values('macro_f1', ascending=False)\n",
    "display(resampling_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Classification Comparison and Diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Collect no-leak models in one comparison table\n",
    "noleak_baselines = baseline_comparison[baseline_comparison['model'].str.startswith('noleak::')]\n",
    "\n",
    "all_cls_results = pd.concat(\n",
    "    [noleak_baselines, weighted_df, resampling_df],\n",
    "    ignore_index=True\n",
    ").sort_values('macro_f1', ascending=False)\n",
    "\n",
    "display(all_cls_results)\n",
    "\n",
    "plot_data = all_cls_results[['model', 'macro_f1', 'balanced_accuracy']].set_index('model')\n",
    "plot_data.plot(kind='bar', figsize=(14, 6), colormap='Set2')\n",
    "plt.title('No-Leak Classification Comparison')\n",
    "plt.ylabel('score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Refit the best no-leak model and inspect class-level performance\n",
    "best_model_name = all_cls_results.iloc[0]['model']\n",
    "\n",
    "model_factory = {\n",
    "    'noleak::dummy_prior': DummyClassifier(strategy='prior', random_state=RANDOM_STATE),\n",
    "    'noleak::logistic_regression': LogisticRegression(max_iter=1200),\n",
    "    'noleak::decision_tree': DecisionTreeClassifier(random_state=RANDOM_STATE, min_samples_leaf=10),\n",
    "    'noleak::random_forest': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    'noleak::logreg_weighted': LogisticRegression(max_iter=1200, class_weight='balanced'),\n",
    "    'noleak::dtree_weighted': DecisionTreeClassifier(random_state=RANDOM_STATE, min_samples_leaf=10, class_weight='balanced'),\n",
    "    'noleak::rf_weighted': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1, class_weight='balanced_subsample'),\n",
    "    'noleak::rf_oversampled': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    'noleak::rf_undersampled': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "}\n",
    "\n",
    "# Use matching train data for resampling variants\n",
    "if best_model_name == 'noleak::rf_oversampled':\n",
    "    X_train_best, y_train_best = X_over, y_over\n",
    "elif best_model_name == 'noleak::rf_undersampled':\n",
    "    X_train_best, y_train_best = X_under, y_under\n",
    "else:\n",
    "    X_train_best, y_train_best = Xn_train, yn_train\n",
    "\n",
    "best_estimator = model_factory[best_model_name]\n",
    "best_pipe, best_pred, best_metrics = fit_eval_classifier(\n",
    "    model_name=best_model_name,\n",
    "    estimator=best_estimator,\n",
    "    X_train=X_train_best,\n",
    "    y_train=y_train_best,\n",
    "    X_test=Xn_test,\n",
    "    y_test=yn_test,\n",
    ")\n",
    "\n",
    "print('Best model:', best_model_name)\n",
    "print(best_metrics)\n",
    "print()\n",
    "print(classification_report(yn_test, best_pred, digits=3))\n",
    "\n",
    "labels = sorted(y.unique())\n",
    "cm = confusion_matrix(yn_test, best_pred, labels=labels)\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Explainability: permutation feature importance on best no-leak model\n",
    "perm = permutation_importance(\n",
    "    estimator=best_pipe,\n",
    "    X=Xn_test,\n",
    "    y=yn_test,\n",
    "    scoring='f1_macro',\n",
    "    n_repeats=5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "fi = pd.DataFrame({\n",
    "    'feature': Xn_test.columns,\n",
    "    'importance_mean': perm.importances_mean,\n",
    "    'importance_std': perm.importances_std,\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "display(fi.head(20))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=fi.head(20), x='importance_mean', y='feature', palette='crest')\n",
    "plt.title('Top 20 Permutation Importances (Macro-F1)')\n",
    "plt.xlabel('Importance (mean decrease)')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Regression Task (Extra)\n",
    "\n",
    "We model a continuous target: `SDS-SDS_Total_T`.\n",
    "\n",
    "Leakage prevention for regression:\n",
    "- remove `SDS-SDS_Total_Raw` (directly related score)\n",
    "- remove `PCIAT-*` columns\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_target = 'SDS-SDS_Total_T'\n",
    "\n",
    "reg_df = df[df[reg_target].notna()].copy()\n",
    "reg_drop = [id_col, reg_target, 'SDS-SDS_Total_Raw'] + pciat_cols\n",
    "reg_drop = [c for c in reg_drop if c is not None]\n",
    "\n",
    "X_reg = reg_df.drop(columns=reg_drop, errors='ignore')\n",
    "y_reg = reg_df[reg_target].astype(float)\n",
    "\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print('Regression rows used:', len(reg_df))\n",
    "print('Regression train/test:', Xr_train.shape, Xr_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Regression helper\n",
    "\n",
    "def fit_eval_regressor(model_name, estimator, X_train, y_train, X_test, y_test):\n",
    "    preprocessor = make_preprocessor(X_train)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('model', estimator),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, pred) ** 0.5\n",
    "\n",
    "    metrics = {\n",
    "        'model': model_name,\n",
    "        'MAE': mean_absolute_error(y_test, pred),\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2_score(y_test, pred),\n",
    "    }\n",
    "\n",
    "    return pipe, pred, metrics\n",
    "\n",
    "\n",
    "reg_models = {\n",
    "    'dummy_mean': DummyRegressor(strategy='mean'),\n",
    "    'rf_regressor': RandomForestRegressor(n_estimators=250, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    'gbr_regressor': GradientBoostingRegressor(random_state=RANDOM_STATE),\n",
    "}\n",
    "\n",
    "reg_rows = []\n",
    "for name, model in reg_models.items():\n",
    "    _, _, m = fit_eval_regressor(name, model, Xr_train, yr_train, Xr_test, yr_test)\n",
    "    reg_rows.append(m)\n",
    "\n",
    "reg_results = pd.DataFrame(reg_rows).sort_values('RMSE')\n",
    "display(reg_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Clustering Analysis (Extra)\n",
    "\n",
    "Unsupervised clustering on no-leak **numeric** features:\n",
    "- median imputation + standardization\n",
    "- silhouette-based selection of `k`\n",
    "- 2D PCA visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_cols = X_no_leak.select_dtypes(include=[np.number]).columns.tolist()\n",
    "X_num = X_no_leak[num_cols].copy()\n",
    "\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X_num_imp = imp.fit_transform(X_num)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_num_scaled = sc.fit_transform(X_num_imp)\n",
    "\n",
    "sil_rows = []\n",
    "for k in range(2, 7):\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=20)\n",
    "    labels = km.fit_predict(X_num_scaled)\n",
    "    sil = silhouette_score(X_num_scaled, labels)\n",
    "    sil_rows.append({'k': k, 'silhouette': sil})\n",
    "\n",
    "sil_df = pd.DataFrame(sil_rows).sort_values('silhouette', ascending=False)\n",
    "display(sil_df)\n",
    "\n",
    "best_k = int(sil_df.iloc[0]['k'])\n",
    "print('Best k from silhouette:', best_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit clustering with best k and visualize clusters in 2D\n",
    "km_best = KMeans(n_clusters=best_k, random_state=RANDOM_STATE, n_init=20)\n",
    "cluster_labels = km_best.fit_predict(X_num_scaled)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_num_scaled)\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'PC1': X_pca[:, 0],\n",
    "    'PC2': X_pca[:, 1],\n",
    "    'cluster': cluster_labels,\n",
    "    'sii': y.values,\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=plot_df, x='PC1', y='PC2', hue='cluster', palette='tab10', s=35, alpha=0.8)\n",
    "plt.title('KMeans Clusters (PCA projection)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cluster_sii = pd.crosstab(plot_df['cluster'], plot_df['sii'], normalize='index').round(3)\n",
    "print('Class composition per cluster (row-normalized):')\n",
    "display(cluster_sii)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Conclusions\n",
    "\n",
    "Key findings:\n",
    "- `sii` is strongly imbalanced, so `macro_f1` and `balanced_accuracy` are required.\n",
    "- `PCIAT-*` variables create strong leakage risk when predicting `sii`; no-leak analysis is more realistic.\n",
    "- in the no-leak setting, model performance is significantly harder and closer to baseline, which is expected.\n",
    "- outlier filtering can be evaluated but may not always improve multiclass metrics.\n",
    "- class weighting and sampling strategies should be compared empirically because gains vary by model and class.\n",
    "- additional regression and clustering analyses provide broader project coverage and exploratory insight.\n",
    "\n",
    "Possible next upgrades:\n",
    "1. hyperparameter tuning with `GridSearchCV`/`RandomizedSearchCV`\n",
    "2. advanced resampling (SMOTE/ADASYN) if `imbalanced-learn` is installed\n",
    "3. threshold/cost-sensitive optimization targeting minority classes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}